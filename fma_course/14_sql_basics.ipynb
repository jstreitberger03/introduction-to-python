{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1d8fde",
   "metadata": {},
   "source": [
    "# SQL for Data Science\n",
    "\n",
    "Data is rarely handed to you in a perfect CSV file. In the real world, it lives in **Relational Databases**. To get this data, you need to speak the database's language: **SQL** (Structured Query Language).\n",
    "\n",
    "Think of a database as a collection of Excel sheets (called \"tables\") that are linked together. SQL lets you ask questions like \"Give me all customers who live in Vienna\" or \"Calculate the average sales for last month.\"\n",
    "\n",
    "## Learning Objectives\n",
    "- **Understand SQL Basics**: Learn the core commands `SELECT` (to pick columns) and `WHERE` (to filter rows).\n",
    "- **Connect with Python**: Use the `sqlite3` library to talk to a database from your Python code.\n",
    "- **Load into Pandas**: The ultimate goalâ€”getting the data out of the database and into a Pandas DataFrame so you can analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5235ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created and populated.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to an in-memory database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create a table\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE employees (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    department TEXT,\n",
    "    salary INTEGER\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Insert some data\n",
    "data = [\n",
    "    (1, \"Alice\", \"Legal\", 60000),\n",
    "    (2, \"Bob\", \"IT\", 70000),\n",
    "    (3, \"Charlie\", \"Legal\", 80000),\n",
    "    (4, \"David\", \"HR\", 55000)\n",
    "]\n",
    "cursor.executemany(\"INSERT INTO employees VALUES (?, ?, ?, ?)\", data)\n",
    "conn.commit()\n",
    "print(\"Database created and populated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e87d26",
   "metadata": {},
   "source": [
    "## 2. Querying with SQL\n",
    "\n",
    "Now that we have data, let's ask questions. The most important command is `SELECT`.\n",
    "\n",
    "*   **`SELECT *`**: The asterisk `*` means \"all columns\".\n",
    "*   **`FROM employees`**: Tells the database which table to look in.\n",
    "*   **`WHERE department = 'Legal'`**: This is a **filter**. It only gives us rows where the condition is true.\n",
    "\n",
    "**Analogy:** Imagine ordering food. \"I want everything (`SELECT *`) from the menu (`FROM menu`) where the type is vegetarian (`WHERE type = 'vegetarian'`).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a query\n",
    "cursor.execute(\"SELECT * FROM employees WHERE department = 'Legal'\")\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "# Query executed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa2f24",
   "metadata": {},
   "source": [
    "## 3. SQL to Pandas\n",
    "\n",
    "In the previous step, we got a list of raw rows. This is okay, but Data Scientists prefer working with **DataFrames**.\n",
    "\n",
    "Pandas has a magic function called `read_sql`. You give it your SQL query and the database connection, and it returns a perfectly formatted DataFrame. This is how you will work 99% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SQL directly into a DataFrame\n",
    "df = pd.read_sql(\"SELECT * FROM employees\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0e26b",
   "metadata": {},
   "source": [
    "## 4. Aggregation in SQL\n",
    "\n",
    "Sometimes the data is too big to load into Python (e.g., 100 million rows). In these cases, you should ask the database to summarize the data *before* sending it to you.\n",
    "\n",
    "*   **`GROUP BY`**: Groups rows together (e.g., \"Put all 'IT' employees in one pile and all 'Legal' employees in another\").\n",
    "*   **`AVG(salary)`**: Calculates the average for each pile.\n",
    "\n",
    "This is much faster than loading all 100 million rows into Python and calculating the average there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT department, AVG(salary) as avg_salary\n",
    "FROM employees\n",
    "GROUP BY department\n",
    "\"\"\"\n",
    "df_agg = pd.read_sql(query, conn)\n",
    "df_agg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
